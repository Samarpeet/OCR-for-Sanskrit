{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samarpeet/OCR-for-Sanskrit/blob/main/REDO_FULL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -q kaggle"
      ],
      "metadata": {
        "id": "7d5H4-J6VFfv"
      },
      "id": "7d5H4-J6VFfv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.upload()"
      ],
      "metadata": {
        "id": "rhSGemYwVOC9"
      },
      "id": "rhSGemYwVOC9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "c9NZdyzGVPG4"
      },
      "id": "c9NZdyzGVPG4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "L5N_3c-KVPPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a14760f-6e0b-4f63-b07d-95396fcd23e6"
      },
      "id": "L5N_3c-KVPPW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "GdJ7jy0PVPS1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed7d821-6840-4841-dde2-bf784b2b5a26"
      },
      "id": "GdJ7jy0PVPS1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "rbWt-6AvVPWT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ea1fb5-51a0-42ee-8a16-65c375e5ea26"
      },
      "id": "rbWt-6AvVPWT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d anurags397/hindi-mnist-data"
      ],
      "metadata": {
        "id": "qhziclnaVPY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8788a8-8e3d-4b05-a0c3-af268fc4f3ee"
      },
      "id": "qhziclnaVPY0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip hindi-mnist-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djUJtwvAVgKc",
        "outputId": "4a83e6b0-9e90-4830-a8b6-57570413a244"
      },
      "id": "djUJtwvAVgKc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open hindi-mnist-data.zip, hindi-mnist-data.zip.zip or hindi-mnist-data.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ma0Uwg5NVgTN"
      },
      "id": "ma0Uwg5NVgTN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siaX9asUVgfj"
      },
      "id": "siaX9asUVgfj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d3e123",
      "metadata": {
        "id": "a9d3e123"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ef6cce",
      "metadata": {
        "id": "b6ef6cce"
      },
      "source": [
        "## Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43b234a6",
      "metadata": {
        "id": "43b234a6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,random_split,TensorDataset\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652dcfa0",
      "metadata": {
        "id": "652dcfa0"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3353fe16",
      "metadata": {
        "id": "3353fe16"
      },
      "outputs": [],
      "source": [
        "project_name = 'sanskrit classification'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d4aca98",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "6d4aca98",
        "outputId": "ca09fab1-2a1a-4654-8d74-26dd3666f721"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bfda60222193>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/DevanagariHandwrittenDigitDataset/Train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/DevanagariHandwrittenDigitDataset/Train'"
          ]
        }
      ],
      "source": [
        "path_folder = \"/content/DevanagariHandwrittenDigitDataset/Train\"\n",
        "os.listdir(path_folder)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zLlTGnaMMVzt"
      },
      "id": "zLlTGnaMMVzt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c42678a6",
      "metadata": {
        "id": "c42678a6"
      },
      "source": [
        "## Number of unique characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95dc0a45",
      "metadata": {
        "id": "95dc0a45"
      },
      "outputs": [],
      "source": [
        "unique_nos = []\n",
        "cl = os.listdir(path_folder)\n",
        "for i in cl:\n",
        "    x = i.split('_')\n",
        "    if x[0] not in unique_nos:\n",
        "        unique_nos.append(x[0])\n",
        "print(\"Number of Unique Characters : \",len(unique_nos))\n",
        "print(\"Unique Characters: \",unique_nos)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f787a7b",
      "metadata": {
        "id": "9f787a7b"
      },
      "source": [
        "## Loading Training and Test Dataset as Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade9f0c5",
      "metadata": {
        "id": "ade9f0c5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((32, 32)),\n",
        "     transforms.ToTensor()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd80bd05",
      "metadata": {
        "id": "dd80bd05"
      },
      "outputs": [],
      "source": [
        "transform_new = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "\n",
        "mean = [0.5, 0.5, 0.5]\n",
        "std = [0.5, 0.5, 0.5]\n",
        "\n",
        "# Compose the transformations\n",
        "transform_new_2 = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=mean, std=std),\n",
        "    transforms.RandomRotation(degrees=15),  # Add random rotation (adjust degrees as needed)\n",
        "    transforms.RandomCrop((32, 32)),  # Add random crop (adjust size as needed)\n",
        "    transforms.GaussianBlur(kernel_size=3)  # Add Gaussian blur (adjust kernel_size as needed)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc5e001",
      "metadata": {
        "scrolled": false,
        "id": "2cc5e001"
      },
      "outputs": [],
      "source": [
        "dataset = ImageFolder(\"/content/DevanagariHandwrittenDigitDataset/Train\",transform=transform_new)\n",
        "test_ds = ImageFolder(\"/content/DevanagariHandwrittenDigitDataset/Test\",transform=transform_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15846780",
      "metadata": {
        "id": "15846780"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d12280b5",
      "metadata": {
        "id": "d12280b5"
      },
      "outputs": [],
      "source": [
        "print(\"Number of training images: \",len(dataset))\n",
        "print(\"Number of testing images: \",len(test_ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0ecf053",
      "metadata": {
        "id": "a0ecf053"
      },
      "source": [
        "### Number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17cc6910",
      "metadata": {
        "id": "17cc6910"
      },
      "outputs": [],
      "source": [
        "num_classes = dataset.classes\n",
        "print(\"Number of classes: \",len(num_classes))\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0047ccf4",
      "metadata": {
        "id": "0047ccf4"
      },
      "source": [
        "### Visualising a single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4703b306",
      "metadata": {
        "id": "4703b306"
      },
      "outputs": [],
      "source": [
        "image, label  = dataset[0]\n",
        "print(\"Image shape:\",image.shape)\n",
        "print(\"Image Label: \",label)\n",
        "print(\"Image Label: \",dataset.classes[label])\n",
        "print(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cdc69ad",
      "metadata": {
        "id": "1cdc69ad"
      },
      "outputs": [],
      "source": [
        "image, label  = dataset[0]\n",
        "fig,(ax1,ax2) = plt.subplots(figsize=(15,5),nrows=1,ncols=2)\n",
        "ax1.imshow(image.permute(1,2,0))\n",
        "ax1.set_title(\"original image\")\n",
        "ax2.imshow(1-image.permute(1,2,0))\n",
        "ax2.set_title(\"inverted image\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e87d98",
      "metadata": {
        "id": "f0e87d98"
      },
      "source": [
        "# Validation Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49feac97",
      "metadata": {
        "id": "49feac97"
      },
      "outputs": [],
      "source": [
        "random_seed = 42\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3582b892",
      "metadata": {
        "id": "3582b892"
      },
      "outputs": [],
      "source": [
        "validation_split = 0.3\n",
        "val_size = int(len(dataset) * validation_split)\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds,val_ds = random_split(dataset,[train_size,val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea610c4b",
      "metadata": {
        "id": "ea610c4b"
      },
      "outputs": [],
      "source": [
        "# batch_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(train_ds,batch_size=batch_size,num_workers=2,shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds,batch_size=batch_size,num_workers=2,shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_ds,batch_size=batch_size,num_workers=2,shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13e5c78e",
      "metadata": {
        "id": "13e5c78e"
      },
      "source": [
        "## Visualising a Batch of images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca80cc3",
      "metadata": {
        "id": "1ca80cc3"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "# Limit the number of batches processed for testing\n",
        "subset_loader = itertools.islice(train_loader, 5)  # Change '5' to the desired number of batches\n",
        "\n",
        "for batch in subset_loader:\n",
        "    for image in batch:\n",
        "        # Check the shape of each image\n",
        "        print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e95741f8",
      "metadata": {
        "id": "e95741f8"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e2b6764",
      "metadata": {
        "id": "1e2b6764"
      },
      "source": [
        "### Building a Base Image Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5e8dea",
      "metadata": {
        "id": "6d5e8dea"
      },
      "outputs": [],
      "source": [
        "def accuracy(outputs, labels):\n",
        "  _, preds = torch.max(outputs, dim=1)\n",
        "  return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "\n",
        "class ImageClassificationBase(nn.Module): #nn.Module, which is the base class for all PyTorch models.\n",
        "\n",
        "  def training_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self,batch):\n",
        "    images,labels = batch\n",
        "    out = self(images)\n",
        "    loss = F.cross_entropy(out,labels)\n",
        "    acc = accuracy(out,labels)\n",
        "    return {'val_loss':loss,'val_acc':acc}\n",
        "\n",
        "  def validation_epoch_end(self,outputs):\n",
        "    batch_loss = [out['val_loss'] for out in outputs]\n",
        "    epoch_loss = torch.stack(batch_loss).mean()\n",
        "    batch_acc = [out['val_acc'] for out in outputs]\n",
        "    epoch_acc = torch.stack(batch_acc).mean()\n",
        "    return {'val_loss':epoch_loss.item(),'val_acc':epoch_acc.item()}\n",
        "\n",
        "  def epoch_end(self,epoch,result):\n",
        "    print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['train_loss'], result['val_loss'], result['val_acc']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b3f178",
      "metadata": {
        "id": "36b3f178"
      },
      "source": [
        "## Buiding a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a558de19",
      "metadata": {
        "id": "a558de19"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class Sanskrit_characters_Model_cnn(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)  # Assuming 10 classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.network(x)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        _, preds = torch.max(outputs.cpu(), dim=1)  # Ensure predictions are on CPU\n",
        "        return {'val_loss': loss, 'labels': labels, 'preds': preds}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        # Extract losses and labels\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.tensor(batch_losses).mean()  # Calculate mean loss\n",
        "\n",
        "        # Extract labels and predictions\n",
        "        all_labels = torch.cat([x['labels'] for x in outputs])\n",
        "        all_preds = torch.cat([x['preds'] for x in outputs])\n",
        "\n",
        "        # Calculate accuracy\n",
        "        val_acc = accuracy_score(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n",
        "\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': val_acc}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(f\"Epoch [{epoch+1}], train_loss: {result['train_loss']:.4f}, val_loss: {result['val_loss']:.4f}, val_acc: {result['val_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0569c69",
      "metadata": {
        "id": "b0569c69"
      },
      "source": [
        "## Building a VGG16 model using Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f708f1c4",
      "metadata": {
        "id": "f708f1c4"
      },
      "outputs": [],
      "source": [
        "class Sanskrit_characters_Model_VGG16(ImageClassificationBase):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = models.vgg16(pretrained=True)\n",
        "    num_ftrs = self.network.classifier[6].in_features\n",
        "    # Change the fully connected layer for 10 classes\n",
        "    self.network.classifier[6] = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    out = self.network(xb)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8d62809",
      "metadata": {
        "id": "e8d62809"
      },
      "source": [
        "## Building a resnet34 model using Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f86c9a5c",
      "metadata": {
        "id": "f86c9a5c"
      },
      "outputs": [],
      "source": [
        "class Sanskrit_characters_Model2(ImageClassificationBase):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = models.resnet34(pretrained=True)\n",
        "    num_ftrs = self.network.fc.in_features\n",
        "    self.network.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "  def forward(self,xb):\n",
        "    out = self.network(xb)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5466aa26",
      "metadata": {
        "id": "5466aa26"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5e9e518",
      "metadata": {
        "id": "f5e9e518"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model,val_loader):\n",
        "  model.eval()\n",
        "  outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "  return model.validation_epoch_end(outputs)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_cnn(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for batch in val_loader:\n",
        "        images, labels = batch\n",
        "        # Move the batch to the appropriate device (CPU or GPU)\n",
        "        images = images.to('cuda')  # Move the images to the GPU\n",
        "        labels = labels.to('cuda')  # Move the labels to the GPU\n",
        "        output = model(images)\n",
        "        loss = F.cross_entropy(output, labels)\n",
        "        _, preds = torch.max(output, dim=1)\n",
        "        outputs.append({'val_loss': loss.item(), 'labels': labels.cpu(), 'preds': preds.cpu()})\n",
        "    return model.validation_epoch_end(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "887807c6",
      "metadata": {
        "id": "887807c6"
      },
      "outputs": [],
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in tqdm(train_loader):\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)  # Passing the correct arguments\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da88929f",
      "metadata": {
        "id": "da88929f"
      },
      "source": [
        "# Using GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1424df74",
      "metadata": {
        "id": "1424df74"
      },
      "outputs": [],
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "480ff4a7",
      "metadata": {
        "id": "480ff4a7"
      },
      "outputs": [],
      "source": [
        "device = get_default_device()\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423b3b04",
      "metadata": {
        "id": "423b3b04"
      },
      "outputs": [],
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06179095",
      "metadata": {
        "id": "06179095"
      },
      "outputs": [],
      "source": [
        "model = to_device(Sanskrit_characters_Model2(), device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70e4eb2e",
      "metadata": {
        "id": "70e4eb2e"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2eafce7",
      "metadata": {
        "id": "d2eafce7"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23e43493",
      "metadata": {
        "scrolled": true,
        "id": "23e43493"
      },
      "outputs": [],
      "source": [
        "evaluate(model,val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60a2e9c3",
      "metadata": {
        "id": "60a2e9c3"
      },
      "outputs": [],
      "source": [
        " model_cnn = Sanskrit_characters_Model_cnn()\n",
        " model_cnn = model_cnn.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3678d41a",
      "metadata": {
        "id": "3678d41a"
      },
      "outputs": [],
      "source": [
        " evaluate_cnn(model_cnn,val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e35a4f2",
      "metadata": {
        "id": "2e35a4f2"
      },
      "source": [
        "#### VGG 16 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a86d10f",
      "metadata": {
        "id": "6a86d10f"
      },
      "outputs": [],
      "source": [
        "model_vgg16 = to_device(Sanskrit_characters_Model_VGG16(), device)\n",
        "\n",
        "model_vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ceb159",
      "metadata": {
        "id": "b3ceb159"
      },
      "outputs": [],
      "source": [
        "evaluate(model_vgg16,val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "206b1be7",
      "metadata": {
        "id": "206b1be7"
      },
      "source": [
        "#### resnet model running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293dba8d",
      "metadata": {
        "scrolled": true,
        "id": "293dba8d"
      },
      "outputs": [],
      "source": [
        "history = fit(10, 0.001, model, train_loader, val_loader, opt_func = torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d8e8246",
      "metadata": {
        "id": "6d8e8246"
      },
      "source": [
        "#### cnn model running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a480a116",
      "metadata": {
        "id": "a480a116"
      },
      "outputs": [],
      "source": [
        "history_cnn = fit(10, 0.001, model_cnn, train_loader, val_loader, opt_func = torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e115f8",
      "metadata": {
        "id": "b7e115f8"
      },
      "source": [
        "#### vgg16 model running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec1dc5b",
      "metadata": {
        "id": "9ec1dc5b"
      },
      "outputs": [],
      "source": [
        "history_vgg16 = fit(10, 0.001, model_vgg16, train_loader, val_loader, opt_func = torch.optim.Adam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36bcc4fc",
      "metadata": {
        "id": "36bcc4fc"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'SK-resnet.pth')\n",
        "\n",
        "torch.save(model_cnn.state_dict(), 'SK-cnn.pth')\n",
        "\n",
        "torch.save(model_vgg16.state_dict(), 'SK-vgg16.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Accuracy and losses"
      ],
      "metadata": {
        "id": "-ab4YtjZdddD"
      },
      "id": "-ab4YtjZdddD"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs')"
      ],
      "metadata": {
        "id": "Ea6wy0J6dbDS"
      },
      "id": "Ea6wy0J6dbDS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs')"
      ],
      "metadata": {
        "id": "QtK7UvKmdbNJ"
      },
      "id": "QtK7UvKmdbNJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history)\n",
        "\n",
        "plot_accuracies(history_cnn)\n",
        "\n",
        "plot_accuracies(history_vgg16)"
      ],
      "metadata": {
        "id": "CeqAb227dbQc"
      },
      "id": "CeqAb227dbQc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history)"
      ],
      "metadata": {
        "id": "UfULTyapdbTe"
      },
      "id": "UfULTyapdbTe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history_cnn)"
      ],
      "metadata": {
        "id": "3dYlJC_Xd7qP"
      },
      "id": "3dYlJC_Xd7qP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history_vgg16)"
      ],
      "metadata": {
        "id": "8Y0mAs-0eE7K"
      },
      "id": "8Y0mAs-0eE7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model,val_loader)"
      ],
      "metadata": {
        "id": "1nzi1n5HeSaD"
      },
      "id": "1nzi1n5HeSaD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_cnn(model_cnn,val_loader)"
      ],
      "metadata": {
        "id": "h7sxhP6oeSqv"
      },
      "id": "h7sxhP6oeSqv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model_vgg16,val_loader)"
      ],
      "metadata": {
        "id": "lf2k0UQLeSyl"
      },
      "id": "lf2k0UQLeSyl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dbe80c33",
      "metadata": {
        "id": "dbe80c33"
      },
      "source": [
        "## Evaluation and Prediction on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74da96c4",
      "metadata": {
        "id": "74da96c4"
      },
      "outputs": [],
      "source": [
        "x = evaluate(model,test_loader)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff83bd36",
      "metadata": {
        "id": "ff83bd36"
      },
      "outputs": [],
      "source": [
        " x = evaluate_cnn(model_cnn,test_loader)\n",
        " x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6344fe10",
      "metadata": {
        "id": "6344fe10"
      },
      "outputs": [],
      "source": [
        "x = evaluate(model_vgg16,test_loader)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction on some single image of test data"
      ],
      "metadata": {
        "id": "XUs_NVDLe33Q"
      },
      "id": "XUs_NVDLe33Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb39db03",
      "metadata": {
        "id": "eb39db03"
      },
      "outputs": [],
      "source": [
        "def predict_image(img, model):\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    yb = model(xb)\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "    return dataset.classes[preds[0].item()]\n",
        "\n",
        "def predict_image_cnn(img, model):\n",
        "    # Move the input image tensor to the appropriate device (CPU or GPU)\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Ensure the model and input tensor are on the same device\n",
        "    model = model.to(device)\n",
        "    yb = model(xb)\n",
        "    _, preds = torch.max(yb, dim=1)\n",
        "    return dataset.classes[preds[0].item()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddb5c23b",
      "metadata": {
        "id": "ddb5c23b"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[1300]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('    Label:', dataset.classes[label])\n",
        "print('Predicted:', predict_image(img, model))\n",
        "print('--------')\n",
        "\n",
        "img, label = test_ds[1300]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('    Label:', dataset.classes[label])\n",
        "print('Predicted:', predict_image(img, model_vgg16))\n",
        "print('--------')\n",
        "\n",
        "img, label = test_ds[1300]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('    Label:', dataset.classes[label])\n",
        "print('Predicted:', predict_image_cnn(img, model_cnn))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2decde3a",
      "metadata": {
        "id": "2decde3a"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[980]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))\n",
        "\n",
        "img, label = test_ds[980]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model_vgg16))\n",
        "\n",
        "img, label = test_ds[980]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image_cnn(img, model_cnn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4a6f89",
      "metadata": {
        "id": "2a4a6f89"
      },
      "outputs": [],
      "source": [
        "img, label = test_ds[254]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))\n",
        "\n",
        "img, label = test_ds[254]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model_vgg16))\n",
        "\n",
        "img, label = test_ds[254]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image_cnn(img, model_cnn))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# Assuming `model` is your trained model\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:  # Assuming you want to evaluate on the test dataset\n",
        "        images, labels = batch\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute the F1 score, precision, and recall\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "precision = precision_score(all_labels, all_preds, average='weighted')\n",
        "recall = recall_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "# Display the results\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# # If you want a detailed report by class\n",
        "# class_names = dataset.classes  # Use the class names from your dataset\n",
        "# report = classification_report(all_labels, all_preds, target_names=class_names)\n",
        "# print(report)\n"
      ],
      "metadata": {
        "id": "gFjy3h-0fXlK"
      },
      "id": "gFjy3h-0fXlK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OvRz-IgAfb8U"
      },
      "id": "OvRz-IgAfb8U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UGRjjy6Efb_k"
      },
      "id": "UGRjjy6Efb_k",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}